#!/bin/bash
cd ../
#python main_finetune.py Optim.lr=0.000001 Data.name=mmwhsmr Trainer.num_batches=200 Arch.num_classes=5 Arch.input_dim=1 RandomSeed=10  Trainer.max_epoch=100 Trainer.name=finetune Trainer.save_dir=0508/lr_case1
#python main_finetune.py Optim.lr=0.000005  Data.name=mmwhsmr Trainer.num_batches=200 Arch.num_classes=5 Arch.input_dim=1 RandomSeed=10  Trainer.max_epoch=100 Trainer.name=finetune Trainer.save_dir=0508/lr_case2
#
#python main_finetune.py Optim.lr=0.0000001 Data.name=mmwhsmr Trainer.num_batches=200 Arch.num_classes=5 Arch.input_dim=1 RandomSeed=10  Trainer.max_epoch=100 Trainer.name=finetune Trainer.save_dir=0508/lr_case3
#python main_finetune.py Optim.lr=0.0000005  Data.name=mmwhsmr Trainer.num_batches=200 Arch.num_classes=5 Arch.input_dim=1 RandomSeed=10  Trainer.max_epoch=100 Trainer.name=finetune Trainer.save_dir=0508/lr_case4
#
#python main_finetune.py Optim.lr=0.00001 Data.name=mmwhsmr Trainer.num_batches=200 Arch.num_classes=5 Arch.input_dim=1 RandomSeed=10  Trainer.max_epoch=100 Trainer.name=finetune Trainer.save_dir=0508/lr_case5
#python main_finetune.py Optim.lr=0.00005  Data.name=mmwhsmr Trainer.num_batches=200 Arch.num_classes=5 Arch.input_dim=1 RandomSeed=10  Trainer.max_epoch=100 Trainer.name=finetune Trainer.save_dir=0508/lr_case6
#
#python main_finetune.py Optim.lr=0.0001 Data.name=mmwhsmr Trainer.num_batches=200 Arch.num_classes=5 Arch.input_dim=1 RandomSeed=10  Trainer.max_epoch=100 Trainer.name=finetune Trainer.save_dir=0508/lr_case7
python main_finetune.py Optim.lr=0.0005  Data.name=mmwhsmr Trainer.num_batches=200 Arch.num_classes=5 Arch.input_dim=1 RandomSeed=10  Trainer.max_epoch=100 Trainer.name=finetune Trainer.save_dir=0508/lr_case8
